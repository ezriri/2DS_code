{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0061fdff-41f8-4a76-a7fb-a1c3fd8e0252",
   "metadata": {},
   "source": [
    "### spare code\n",
    "useful at the time, but not any more, may be useful in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9971aaa3-72db-46ed-a178-b431e7a045d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_crystal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# so if we have an image with multiple things inside, we just want the biggest crystal -> want to return the index of these, so can just use it to extract it\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Convert the dataframe to a binary image where 0 is True (activated) and all else is False\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m binary_image \u001b[38;5;241m=\u001b[39m (\u001b[43mone_crystal\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Label the connected components\u001b[39;00m\n\u001b[1;32m      6\u001b[0m labeled_image, num_features \u001b[38;5;241m=\u001b[39m label(binary_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_crystal' is not defined"
     ]
    }
   ],
   "source": [
    "# so if we have an image with multiple things inside, we just want the biggest crystal -> want to return the index of these, so can just use it to extract it\n",
    "# Convert the dataframe to a binary image where 0 is True (activated) and all else is False\n",
    "binary_image = (one_crystal == 0)\n",
    "\n",
    "# Label the connected components\n",
    "labeled_image, num_features = label(binary_image)\n",
    "\n",
    "plt.imshow(binary_image, cmap='gray')\n",
    "\n",
    "props = regionprops(labeled_image)\n",
    "if props:\n",
    "    # Find the component with the maximum area\n",
    "    largest_component = max(props, key=lambda x: x.area)\n",
    "    print(largest_component)\n",
    "\n",
    "    # Extract x-values (column indices) of the largest component\n",
    "    coords = largest_component.coords\n",
    "    x_values = np.unique(coords[:, 1])  # column indices are the x-values\n",
    "else:\n",
    "    x_values = np.array([])  # No components found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b77e9-6ed2-49aa-abcc-5f2c03b0f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions for particle calculations\n",
    "## Min + Max dimensions calculation - Feret Diameters\n",
    "# found other thing worked better\n",
    "\n",
    "def calculate_feret_diameters(points):\n",
    "    \"\"\"Calculate both minimum and maximum Feret diameters using the convex hull and rotating calipers.\"\"\"\n",
    "    # Check if all points are collinear\n",
    "    if np.linalg.matrix_rank(points - points[0]) < 2:\n",
    "        # Calculate maximum and minimum distances between points as they are on a line\n",
    "        dists = distance_matrix(points, points)\n",
    "        max_feret = np.max(dists)\n",
    "        min_feret = np.min(dists[dists > 0])  # Exclude zero distance (self to self)\n",
    "        return min_feret, max_feret\n",
    "        \n",
    "    hull = ConvexHull(points)\n",
    "    hull_points = points[hull.vertices]\n",
    "    \n",
    "    min_diameter = np.inf  # Start with infinitely large diameter\n",
    "    max_diameter = 0  # Start with zero diameter\n",
    "    num_vertices = len(hull_points)\n",
    "\n",
    "    for i in range(num_vertices):\n",
    "        j = (i + 1) % num_vertices\n",
    "        p1, p2 = hull_points[i], hull_points[j]\n",
    "        # Vector from p1 to p2\n",
    "        edge_vec = p2 - p1\n",
    "        edge_length = np.linalg.norm(edge_vec)\n",
    "        max_diameter = max(max_diameter, edge_length)  # Maximum Feret diameter\n",
    "        \n",
    "        # Normalize the edge vector\n",
    "        edge_vec /= edge_length\n",
    "        # Project points onto the line normal to the edge\n",
    "        normal_vec = np.array([-edge_vec[1], edge_vec[0]])\n",
    "        projections = np.dot(hull_points - p1, normal_vec)\n",
    "        min_diameter = min(min_diameter, max(projections) - min(projections))  # Minimum Feret diameter\n",
    "    \n",
    "    return min_diameter, max_diameter\n",
    "\n",
    "def feret_diameters(contours):\n",
    "    if contours:\n",
    "        # Assume the largest contour is the main one (if there are multiple)\n",
    "        largest_contour = max(contours, key=lambda x: x.shape[0])\n",
    "        # Using convex hull to calculate Feret diameters\n",
    "        hull = ConvexHull(largest_contour)\n",
    "        hull_points = largest_contour[hull.vertices]\n",
    "    \n",
    "        # Calculate max Feret diameter\n",
    "        dists = distance_matrix(hull_points, hull_points)\n",
    "        max_feret = np.max(dists)\n",
    "    \n",
    "        # Calculate min Feret diameter\n",
    "        min_feret = np.inf\n",
    "        num_vertices = len(hull_points)\n",
    "        for i in range(num_vertices):\n",
    "            j = (i + 1) % num_vertices\n",
    "            p1, p2 = hull_points[i], hull_points[j]\n",
    "            edge_vec = p2 - p1\n",
    "            edge_length = np.linalg.norm(edge_vec)\n",
    "            edge_vec /= edge_length\n",
    "            normal_vec = np.array([-edge_vec[1], edge_vec[0]])\n",
    "            projections = np.dot(hull_points - p1, normal_vec)\n",
    "            min_feret = min(min_feret, max(projections) - min(projections))\n",
    "\n",
    "        return min_feret, max_feret\n",
    "\n",
    "def calculate_feret_diameter(coords):\n",
    "    \"\"\"Calculate the Feret diameter for a set of points.\"\"\"\n",
    "    dist_matrix = distance_matrix(coords, coords)\n",
    "    feret_diameter = np.max(dist_matrix)\n",
    "    return feret_diameter\n",
    "\n",
    "### ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "def calculate_properties(crystal):\n",
    "    dat = {}\n",
    "    #thresh = threshold(crystal.astype('uint8'), 0, 255, THRESH_BINARY + THRESH_OTSU)\n",
    "\n",
    "    # Optionally fill holes\n",
    "    thresh = binary_fill_holes(crystal).astype(int)\n",
    "    contours = measure.find_contours(thresh, 0.5)\n",
    "    # Sort contours by area (largest first) and select the largest contour\n",
    "    contour = max(contours, key=lambda x: x.shape[0])\n",
    "    \n",
    "    # Label the image based on the threshold\n",
    "    labeled_image = measure.label(thresh)\n",
    "    \n",
    "    # Extract properties using regionprops\n",
    "    region = measure.regionprops(labeled_image)[0]  # Assumes largest labeled region corresponds to largest contour\n",
    "    \n",
    "    # Store the extracted properties in the data structure\n",
    "    dat['len'] = region.major_axis_length\n",
    "    dat['wid'] = region.minor_axis_length\n",
    "    dat['area'] = region.area\n",
    "    dat['orientation'] = region.orientation\n",
    "    dat['centroid'] = region.centroid\n",
    "\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e6fff-ccf8-4577-a083-5746d05d974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## old when extracting data from individual crystals\n",
    "## this was within the loop\n",
    "multi[particle.label] = [coords[0][0],coords[-1][0],s_idx,e_idx] # y1,y2,x1,x2 \n",
    "                # x values are our index also needed for extracting time\n",
    "                # i.e. [f2ds['ImageData'][y1:y2,x1:x2]\n",
    "\n",
    "\n",
    "keys = list(multi.keys())\n",
    "extract = f2ds['ImageData'][multi[keys[0]][0]-2:multi[keys[0]][1]+3,multi[keys[0]][2] -2:multi[keys[0]][3]+3] ## added 2 pixel buffer around single crystal\n",
    "start_t = time_xr['utc_time'][multi[keys[0]][2]]\n",
    "end_t = time_xr['utc_time'][multi[keys[0]][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edda0a-5698-407f-af31-10f5b54c6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly 2 images are captured simultaneously, so will have to capture this in the name when extracting i.e. _0 or _1.h5\n",
    "# this is a function to extract the image data + save appropriately\n",
    "\n",
    "def extract_save_image(x, save_location, int='0'):\n",
    "    im_s_idx = time_xr['pix_sum'][x].values\n",
    "    im_e_idx = time_xr['pix_sum'][x+1].values\n",
    "\n",
    "    one_crystal = ds_image[:,im_s_idx:im_e_idx]\n",
    "    \n",
    "    crystal_str = str(time_xr['utc_time'][im_s_idx].values)\n",
    "    individual_file = f'{crystal_str[5:7]}{crystal_str[8:10]}-{crystal_str[11:13]}{crystal_str[14:16]}{crystal_str[17:19]}{crystal_str[20:22]}_{int}.h5'\n",
    "\n",
    "    save_name = save_location+individual_file\n",
    "\n",
    "    print(save_name)\n",
    "    \n",
    "    with h5py.File(save_name, 'w') as f:\n",
    "    # Create a dataset in the HDF5 file\n",
    "        f.create_dataset('data', data=one_crystal)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    if i = 0:\n",
    "        extract_save_image\n",
    "    elif time_xr['utc_time'][i] == time_xr['utc_time'][i-1]:\n",
    "        # this account for repeat in time for two seperate images\n",
    "        extract_save_image(i,save_loc,int='1')\n",
    "\n",
    "    else:\n",
    "        extract_save_image(i,save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c1e95-a677-45f1-9b5b-e27e8b8b492c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83eaf30-bf11-423d-9093-959153627292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracting particles where area is > than specif threshold\n",
    "## taking our cleaned data, where the files are >4 in length\n",
    "\n",
    "# 1. want to find the objects in the sections\n",
    "# 2. identify objects in which the max dimension is > than specific threshold\n",
    "# 3. extract start + end index of said particle\n",
    "#Â 4. use this index to slice + get corresponding UTC time associated with particle\n",
    "\n",
    "area_threshold = 30 # need this minimum number of pixels to be classified\n",
    "pixel_resolution = 10 # mu\n",
    "\n",
    "binary_image = (one_crystal == 0) ## important, convert regions where 0 = True (our bits of interest), all else false\n",
    "\n",
    "particle_data = []\n",
    "\n",
    "# Label the connected components\n",
    "labeled_image, num_features = label(binary_image) # identify connected true areas\n",
    "# labeled_image = array, with each true area given a number to identify them\n",
    "# num_features = number of unique connected components in image. Have to literally have adjacent pixel, not diagonal (this will make them seperate)\n",
    "\n",
    "props = regionprops(labeled_image) # creates quick list of properties describing each feature detected in the image.\n",
    "# has: label, area, centroid, bounding box - for each feature\n",
    "\n",
    "## only doing this if anything there i.e. if props\n",
    "## want to extract only particles that surpass area threshold \n",
    "if props:\n",
    "    multi = {}\n",
    "    for particle in props:\n",
    "        if particle.area >= area_threshold:\n",
    "\n",
    "            ## basic info\n",
    "            coords = particle.coords # basically gives coords of each point of interest\n",
    "            x_values = np.unique(coords[:, 1])\n",
    "            s_idx = int(selected_values[i] + x_values[0])\n",
    "            e_idx = int(selected_values[i] + x_values[-1])\n",
    "            \n",
    "            ## more complex stats\n",
    "            spec_region = stats_description(particle)\n",
    "\n",
    "\n",
    "            ######## TRUNCATION CHECKING ###################\n",
    "                \n",
    "            min_row, min_col, max_row, max_col = spec_region.bbox\n",
    "\n",
    "            '''\n",
    "            print(min_row)\n",
    "            print(min_col)\n",
    "            print(filled_part.shape[0])\n",
    "            print(filled_part.shape[1])\n",
    "            '''\n",
    "\n",
    "            #print(spec_region.convex_area)\n",
    "            #print(spec_region.area)\n",
    "            \n",
    "            ## convex area\n",
    "            convex_threshold = 0.7\n",
    "            \n",
    "            if spec_region.convex_area > 0:\n",
    "                area_ratio = spec_region.area / spec_region.convex_area\n",
    "                if area_ratio < convex_threshold:  # threshold can be set, e.g., 0.9 or 0.8\n",
    "                    print(\"Particle might be truncated.\")\n",
    "\n",
    "            #########\n",
    "\n",
    "\n",
    "            print(spec_region.eccentricity)\n",
    "            print(spec_region.solidity)\n",
    "            # solidity = Ratio of pixels in the region to pixels of the convex hull image \n",
    "            # centroid location? \n",
    "            \n",
    "            # nice way of saving data\n",
    "            particle_data.append({\n",
    "                    #\"image_index\": image_index,\n",
    "                    \"particle_label\": particle.label,\n",
    "                    \"start_index\": s_idx,\n",
    "                    \"end_index\": e_idx,\n",
    "                    \"start_time\": time_xr['utc_time'][s_idx],  # assuming 'time_xr' is pre-defined and syncs with indices\n",
    "                    \"end_time\": time_xr['utc_time'][e_idx],\n",
    "                    \"major_axis_length\": spec_region.major_axis_length * pixel_resolution,\n",
    "                    \"minor_axis_length\": spec_region.minor_axis_length * pixel_resolution,\n",
    "                    \"orientation\": spec_region.orientation,\n",
    "                    \"centroid\": spec_region.centroid,\n",
    "                    \"area\": (spec_region.area * (pixel_resolution**2)),\n",
    "                    \"perimeter\": (spec_region.perimeter * pixel_resolution),\n",
    "                    \"y0\": coords[0][0],\n",
    "                    \"y1\": coords[-1][0]\n",
    "                })\n",
    "            \n",
    "    particle_df = pd.DataFrame(particle_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
